{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sbindal2017-a11y/Langraph_Analytics_AI_Agent/blob/main/Langgraph_CR_Analytics_Agent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langgraph langchain-community google-generativeai pandas -q"
      ],
      "metadata": {
        "id": "Xlzs_CjqMmZm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SECTION 1: IMPORTS & API CONFIGURATION\n",
        "import pandas as pd\n",
        "import json\n",
        "from typing import TypedDict, Dict, Any, List\n",
        "from google.colab import files, userdata\n",
        "import google.generativeai as genai\n",
        "\n",
        "# LangGraph core components\n",
        "from langgraph.graph import StateGraph, END\n",
        "\n",
        "# NOTE: We have REMOVED the checkpointer import for now to solve the error.\n",
        "# We will add it back at the final assembly stage.\n",
        "\n",
        "print(\"âœ… All libraries imported successfully.\")\n",
        "\n",
        "# --- API Key Configuration ---\n",
        "try:\n",
        "    # Action: Make sure your GOOGLE_API_KEY is saved in Colab Secrets (ðŸ”‘)\n",
        "    GOOGLE_API_KEY = userdata.get('KEY')\n",
        "    genai.configure(api_key=GOOGLE_API_KEY)\n",
        "    print(\"âœ… Gemini API configured successfully.\")\n",
        "except Exception as e:\n",
        "    print(\"ðŸš¨ ERROR: Could not configure Gemini API. Please ensure your GOOGLE_API_KEY is set correctly in Colab secrets.\")\n",
        "    # This will stop the script if the API key is not found.\n",
        "    raise e"
      ],
      "metadata": {
        "id": "sCw63hWRM1z8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# SECTION 2: AGENT STATE DEFINITION\n",
        "# ==============================================================================\n",
        "class AgentState(TypedDict):\n",
        "    \"\"\"\n",
        "    The complete state of our CRO Analytics Agent.\n",
        "    This dictionary acts as the agent's memory, carrying data between nodes.\n",
        "    \"\"\"\n",
        "    # --- Inputs from the user ---\n",
        "    user_question: str\n",
        "    raw_data_path: str\n",
        "\n",
        "    # --- Data processed by the agent ---\n",
        "    cleaned_data_path: str\n",
        "    config: Dict[str, Any]\n",
        "    analysis_results: Dict[str, Any]\n",
        "    final_narrative: str\n",
        "\n",
        "    # --- Utility field for error handling ---\n",
        "    error_message: str\n",
        "\n",
        "print(\"âœ… Agent State defined.\")"
      ],
      "metadata": {
        "id": "mjP-S1-yNoRO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==================================\n",
        "# NODE A: Ingest & Clean\n",
        "# Purpose: Reads the user-uploaded CSV file, validates that it has the\n",
        "#          correct columns, and saves a cleaned version for the rest of\n",
        "#          the agent to use.\n",
        "# ==================================\n",
        "def node_a_ingest_and_clean(state: AgentState) -> dict:\n",
        "    \"\"\"Reads the user-uploaded CSV, validates it, and saves a cleaned version.\"\"\"\n",
        "    print(\"\\n[Node A: Ingest & Clean]\")\n",
        "    print(f\"  - Input: raw_data_path='{state.get('raw_data_path')}'\")\n",
        "    EXPECTED_COLUMNS = ['landing page', 'landing page group', 'channel', 'ad campaign', 'date', 'discount%', 'session', 'atc', 'view cart', 'checkout', 'payment', 'purchase']\n",
        "    try:\n",
        "        df = pd.read_csv(state[\"raw_data_path\"])\n",
        "        if not all(col in df.columns for col in EXPECTED_COLUMNS):\n",
        "            return {\"error_message\": \"Schema validation failed. The CSV is missing required columns.\"}\n",
        "\n",
        "        df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
        "        # We remove any rows where the date could not be parsed.\n",
        "        df.dropna(subset=['date'], inplace=True)\n",
        "\n",
        "        cleaned_file_path = 'cleaned_cro_data.csv'\n",
        "        df.to_csv(cleaned_file_path, index=False)\n",
        "        print(f\"  - Output: Cleaned data saved to '{cleaned_file_path}'\")\n",
        "        return {\"cleaned_data_path\": cleaned_file_path}\n",
        "    except Exception as e:\n",
        "        return {\"error_message\": f\"Node A failed: {e}\"}"
      ],
      "metadata": {
        "id": "Qc6uLM3iN5E8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==================================\n",
        "# NODE B: Generate Config\n",
        "# Purpose: Uses the Gemini AI to interpret the user's natural language\n",
        "#          question and convert it into a structured JSON configuration\n",
        "#          that will control the rest of the analysis.\n",
        "# ==================================\n",
        "def node_b_generate_config(state: AgentState) -> dict:\n",
        "    \"\"\"Uses Gemini to parse the user's question into a JSON config.\"\"\"\n",
        "    print(\"\\n[Node B: Generate Config]\")\n",
        "    print(f\"  - Input: user_question='{state.get('user_question')[:60]}...'\")\n",
        "    try:\n",
        "        df = pd.read_csv(state[\"cleaned_data_path\"])\n",
        "        data_min_date = pd.to_datetime(df['date']).min().strftime('%Y-%m-%d')\n",
        "        data_max_date = pd.to_datetime(df['date']).max().strftime('%Y-%m-%d')\n",
        "        model = genai.GenerativeModel(\"gemini-2.5-pro\")\n",
        "        prompt = f\"\"\"\n",
        "        Dataset dates are from {data_min_date} to {data_max_date}. Today is {pd.to_datetime('today').strftime('%Y-%m-%d')}.\n",
        "        User question: \"{state['user_question']}\"\n",
        "        Your task is to create a JSON config. If the user does not provide enough information to determine both an `analysis_window` and a `baseline_window`, you MUST return `{{\"need_dates\": true, \"message\": \"Please provide both an analysis and a baseline date range.\"}}`.\n",
        "        The schema must be: `{{\"question\": \"...\", \"analysis_window\": {{...}}, \"baseline_window\": {{...}}, \"filters\": {{...}}, \"thresholds\": {{\"TOP_K\": 8, \"MIN_SEG_SHARE\": 0.01}}, \"dims\": [\"channel\", \"ad_campaign\", \"landing_page_group\", \"landing_page\"], \"cr_definition\": \"session_cr\"}}`.\n",
        "        If the user filters on a dimension (e.g., channel=\"google\"), you MUST remove that dimension from the `dims` array.\n",
        "        Output only the raw JSON text.\n",
        "        \"\"\"\n",
        "        response = model.generate_content(prompt)\n",
        "        # Clean the response to ensure it's valid JSON\n",
        "        config_string = response.text.strip().replace(\"```json\", \"\").replace(\"```\", \"\")\n",
        "        config = json.loads(config_string)\n",
        "        print(\"  - Output: Gemini generated the config dictionary.\")\n",
        "        return {\"config\": config}\n",
        "    except Exception as e:\n",
        "        return {\"error_message\": f\"Node B failed: {e}\"}"
      ],
      "metadata": {
        "id": "vtaPOpGkOjaw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# NODE C: Calculate Metrics\n",
        "# Purpose: The first deterministic math node. It takes the configuration\n",
        "#          from Node B and the cleaned data from Node A to calculate\n",
        "#          the top-line metrics (e.g., overall CR and the change).\n",
        "# ==================================\n",
        "def node_c_calculate_metrics(state: AgentState) -> dict:\n",
        "    \"\"\"Calculates the top-line metrics for the two periods.\"\"\"\n",
        "    print(\"\\n[Node C: Calculate Metrics]\")\n",
        "    try:\n",
        "        config = state[\"config\"]\n",
        "        df = pd.read_csv(state[\"cleaned_data_path\"])\n",
        "        df['date'] = pd.to_datetime(df['date'])\n",
        "\n",
        "        aw = config['analysis_window']\n",
        "        bw = config['baseline_window']\n",
        "\n",
        "        # Use .copy() to prevent SettingWithCopyWarning and ensure data integrity\n",
        "        df_analysis = df[df['date'].between(pd.to_datetime(aw['start']), pd.to_datetime(aw['end']))].copy()\n",
        "        df_baseline = df[df['date'].between(pd.to_datetime(bw['start']), pd.to_datetime(bw['end']))].copy()\n",
        "        print(f\"  - DEBUG: Columns available for analysis: {df_analysis.columns.tolist()}\")\n",
        "\n",
        "        # Calculate CR for both periods\n",
        "        analysis_cr = (df_analysis['purchase'].sum() / df_analysis['session'].sum()) * 100 if df_analysis['session'].sum() > 0 else 0\n",
        "        baseline_cr = (df_baseline['purchase'].sum() / df_baseline['session'].sum()) * 100 if df_baseline['session'].sum() > 0 else 0\n",
        "        delta_cr_pp = analysis_cr - baseline_cr\n",
        "\n",
        "        # Convert date columns to strings to ensure they are JSON serializable\n",
        "        df_analysis['date'] = df_analysis['date'].dt.strftime('%Y-%m-%d')\n",
        "        df_baseline['date'] = df_baseline['date'].dt.strftime('%Y-%m-%d')\n",
        "\n",
        "        analysis_results = {\n",
        "            \"summary\": {\"analysis_cr_pct\": round(analysis_cr, 2), \"baseline_cr_pct\": round(baseline_cr, 2), \"delta_cr_pp\": round(delta_cr_pp, 2)},\n",
        "            # Pass the detailed dataframes on to the next nodes\n",
        "            \"dataframes\": {\"analysis\": df_analysis.to_dict('records'), \"baseline\": df_baseline.to_dict('records')}\n",
        "        }\n",
        "        print(\"  - Output: analysis_results dictionary created.\")\n",
        "        return {\"analysis_results\": analysis_results}\n",
        "    except Exception as e:\n",
        "        return {\"error_message\": f\"Node C failed: {e}\"}"
      ],
      "metadata": {
        "id": "hoMdfegkOuXf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==================================\n",
        "# NODE D: AI Analyst\n",
        "# Purpose: Uses Gemini to perform a qualitative scan of the data,\n",
        "#          identifying high-level patterns and outliers like a human analyst.\n",
        "# ==================================\n",
        "def node_d_ai_analyst(state: AgentState) -> dict:\n",
        "    \"\"\"Performs qualitative analysis using Gemini.\"\"\"\n",
        "    print(\"\\n[Node D: AI Analyst]\")\n",
        "    try:\n",
        "        analysis_results = state[\"analysis_results\"]\n",
        "        # Recreate DataFrames from the dictionary records passed in the state\n",
        "        df_analysis = pd.DataFrame(analysis_results[\"dataframes\"][\"analysis\"])\n",
        "        df_baseline = pd.DataFrame(analysis_results[\"dataframes\"][\"baseline\"])\n",
        "\n",
        "        # --- Data Simplification for the AI ---\n",
        "        # Create simple summary tables to send to the AI\n",
        "        summary_analysis = df_analysis.groupby('channel').agg(sessions=('session', 'sum'), purchases=('purchase', 'sum')).reset_index()\n",
        "        summary_analysis['cr'] = (summary_analysis['purchases'] / summary_analysis['sessions']) * 100\n",
        "        summary_baseline = df_baseline.groupby('channel').agg(sessions=('session', 'sum'), purchases=('purchase', 'sum')).reset_index()\n",
        "        summary_baseline['cr'] = (summary_baseline['purchases'] / summary_baseline['sessions']) * 100\n",
        "\n",
        "        model = genai.GenerativeModel(\"gemini-2.5-pro\")\n",
        "        prompt = f\"\"\"\n",
        "        You are analyzing why a website's conversion rate changed from {analysis_results['summary']['baseline_cr_pct']:.2f}% to {analysis_results['summary']['analysis_cr_pct']:.2f}%.\n",
        "        Baseline Period Performance by Channel:\n",
        "        {summary_baseline.to_string()}\n",
        "\n",
        "        Analysis Period Performance by Channel:\n",
        "        {summary_analysis.to_string()}\n",
        "\n",
        "        Based on these tables, what are the 2-3 most important, high-level qualitative observations? Be concise.\n",
        "        Provide your response as a JSON object with a single key \"observations\", which is a list of strings.\n",
        "        \"\"\"\n",
        "        response = model.generate_content(prompt)\n",
        "        qualitative_analysis = json.loads(response.text.strip().replace(\"```json\", \"\").replace(\"```\", \"\"))\n",
        "\n",
        "        # Add the AI's insights back into the main analysis object\n",
        "        analysis_results[\"qualitative_analysis\"] = qualitative_analysis\n",
        "        print(\"  - Output: Added 'qualitative_analysis' to analysis_results.\")\n",
        "        return {\"analysis_results\": analysis_results}\n",
        "    except Exception as e:\n",
        "        return {\"error_message\": f\"Node D failed: {e}\"}"
      ],
      "metadata": {
        "id": "9yJPB3qgO21W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==================================\n",
        "# NODE E: Performance Diagnostics\n",
        "# Purpose: Calculates the 'performance contribution' for each segment. This\n",
        "#          isolates the impact of a segment's own CR changing, holding\n",
        "#          its traffic share constant.\n",
        "# ==================================\n",
        "def node_e_performance_diagnostics(state: AgentState) -> dict:\n",
        "    \"\"\"Calculates performance contribution of each segment.\"\"\"\n",
        "    print(\"\\n[Node E: Performance Diagnostics]\")\n",
        "    try:\n",
        "        config = state[\"config\"]\n",
        "        analysis_results = state[\"analysis_results\"]\n",
        "        df_analysis = pd.DataFrame(analysis_results[\"dataframes\"][\"analysis\"])\n",
        "        df_baseline = pd.DataFrame(analysis_results[\"dataframes\"][\"baseline\"])\n",
        "        dims_to_analyze = config.get(\"dims\", [])\n",
        "        drivers = []\n",
        "\n",
        "        total_sessions_analysis = df_analysis['session'].sum()\n",
        "        if total_sessions_analysis == 0:\n",
        "            return {\"error_message\": \"Cannot calculate performance, total sessions in analysis period is zero.\"}\n",
        "\n",
        "        for dim in dims_to_analyze:\n",
        "            # Aggregate data by the current dimension\n",
        "            group_analysis = df_analysis.groupby(dim).agg(sessions=('session', 'sum'), purchases=('purchase', 'sum')).reset_index()\n",
        "            group_baseline = df_baseline.groupby(dim).agg(sessions=('session', 'sum'), purchases=('purchase', 'sum')).reset_index()\n",
        "\n",
        "            # Calculate CR and traffic share (weight)\n",
        "            group_analysis['cr'] = (group_analysis['purchases'] / group_analysis['sessions']) * 100\n",
        "            group_analysis['weight'] = group_analysis['sessions'] / total_sessions_analysis\n",
        "            group_baseline['cr'] = (group_baseline['purchases'] / group_baseline['sessions']) * 100\n",
        "\n",
        "            merged = pd.merge(group_analysis, group_baseline, on=dim, suffixes=('_analysis', '_baseline'), how='outer').fillna(0)\n",
        "\n",
        "            # Performance Contribution Formula: weight_analysis * (cr_analysis - cr_baseline)\n",
        "            merged['perf_contribution_pp'] = merged['weight_analysis'] * (merged['cr_analysis'] - merged['cr_baseline'])\n",
        "\n",
        "            for _, row in merged.iterrows():\n",
        "                if abs(row['perf_contribution_pp']) > 0.001: # Ignore negligible contributions\n",
        "                    drivers.append({\n",
        "                        \"driver\": f\"{dim}: {row[dim]}\",\n",
        "                        \"delta_pp\": round(row['perf_contribution_pp'], 3),\n",
        "                        \"type\": \"performance\"\n",
        "                    })\n",
        "\n",
        "        analysis_results[\"drivers_performance\"] = drivers\n",
        "        print(f\"  - Output: Calculated {len(drivers)} performance drivers.\")\n",
        "        return {\"analysis_results\": analysis_results}\n",
        "    except Exception as e:\n",
        "        return {\"error_message\": f\"Node E failed: {e}\"}"
      ],
      "metadata": {
        "id": "nEpOcp9TPH4s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==================================\n",
        "# NODE F: Mix Diagnostics\n",
        "# Purpose: Calculates the 'mix contribution' for each segment. This\n",
        "#          isolates the impact of traffic shifting towards or away from\n",
        "#          a segment, holding its CR constant at baseline levels.\n",
        "# ==================================\n",
        "def node_f_mix_diagnostics(state: AgentState) -> dict:\n",
        "    \"\"\"Calculates mix shift contribution of each segment.\"\"\"\n",
        "    print(\"\\n[Node F: Mix Diagnostics]\")\n",
        "    try:\n",
        "        config = state[\"config\"]\n",
        "        analysis_results = state[\"analysis_results\"]\n",
        "        df_analysis = pd.DataFrame(analysis_results[\"dataframes\"][\"analysis\"])\n",
        "        df_baseline = pd.DataFrame(analysis_results[\"dataframes\"][\"baseline\"])\n",
        "        dims_to_analyze = config.get(\"dims\", [])\n",
        "        drivers = []\n",
        "\n",
        "        total_sessions_analysis = df_analysis['session'].sum()\n",
        "        total_sessions_baseline = df_baseline['session'].sum()\n",
        "        if total_sessions_analysis == 0 or total_sessions_baseline == 0:\n",
        "            return {\"error_message\": \"Cannot calculate mix, total sessions is zero in one or both periods.\"}\n",
        "\n",
        "        for dim in dims_to_analyze:\n",
        "            # Aggregate data by the current dimension\n",
        "            group_analysis = df_analysis.groupby(dim).agg(sessions=('session', 'sum'), purchases=('purchase', 'sum')).reset_index()\n",
        "            group_baseline = df_baseline.groupby(dim).agg(sessions=('session', 'sum'), purchases=('purchase', 'sum')).reset_index()\n",
        "\n",
        "            # Calculate CR and traffic share (weight) for both periods\n",
        "            group_analysis['weight'] = group_analysis['sessions'] / total_sessions_analysis\n",
        "            group_baseline['cr'] = (group_baseline['purchases'] / group_baseline['sessions']) * 100\n",
        "            group_baseline['weight'] = group_baseline['sessions'] / total_sessions_baseline\n",
        "\n",
        "            merged = pd.merge(group_analysis, group_baseline, on=dim, suffixes=('_analysis', '_baseline'), how='outer').fillna(0)\n",
        "\n",
        "            # Mix Contribution Formula: (weight_analysis - weight_baseline) * cr_baseline\n",
        "            merged['mix_contribution_pp'] = (merged['weight_analysis'] - merged['weight_baseline']) * merged['cr_baseline']\n",
        "\n",
        "            for _, row in merged.iterrows():\n",
        "                if abs(row['mix_contribution_pp']) > 0.001: # Ignore negligible contributions\n",
        "                    drivers.append({\n",
        "                        \"driver\": f\"{dim}: {row[dim]}\",\n",
        "                        \"delta_pp\": round(row['mix_contribution_pp'], 3),\n",
        "                        \"type\": \"mix\"\n",
        "                    })\n",
        "\n",
        "        analysis_results[\"drivers_mix\"] = drivers\n",
        "        print(f\"  - Output: Calculated {len(drivers)} mix drivers.\")\n",
        "        return {\"analysis_results\": analysis_results}\n",
        "    except Exception as e:\n",
        "        return {\"error_message\": f\"Node F failed: {e}\"}"
      ],
      "metadata": {
        "id": "dBf4Yfe3PM4d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==================================\n",
        "# NODE G: Waterfall Composer\n",
        "# Purpose: Merges the performance and mix drivers into a single, sorted\n",
        "#          list. It also calculates any unexplained variance to ensure\n",
        "#          the analysis perfectly reconciles with the total change.\n",
        "# ==================================\n",
        "def node_g_compose_waterfall(state: AgentState) -> dict:\n",
        "    \"\"\"Merges and sorts all drivers into a final list.\"\"\"\n",
        "    print(\"\\n[Node G: Compose Waterfall]\")\n",
        "    try:\n",
        "        analysis_results = state[\"analysis_results\"]\n",
        "        drivers_performance = analysis_results.get(\"drivers_performance\", [])\n",
        "        drivers_mix = analysis_results.get(\"drivers_mix\", [])\n",
        "\n",
        "        # Combine all drivers into one list\n",
        "        all_drivers = drivers_performance + drivers_mix\n",
        "\n",
        "        # Sort drivers by the absolute value of their impact\n",
        "        all_drivers.sort(key=lambda x: abs(x[\"delta_pp\"]), reverse=True)\n",
        "\n",
        "        # Reconcile the sum of drivers with the total change\n",
        "        total_delta_cr = analysis_results[\"summary\"][\"delta_cr_pp\"]\n",
        "        sum_of_drivers = sum(d[\"delta_pp\"] for d in all_drivers)\n",
        "        unexplained_pp = total_delta_cr - sum_of_drivers\n",
        "\n",
        "        analysis_results[\"drivers_final\"] = all_drivers\n",
        "        analysis_results[\"unexplained_pp\"] = round(unexplained_pp, 3)\n",
        "\n",
        "        print(f\"  - Output: Composed a final list of {len(all_drivers)} drivers.\")\n",
        "        return {\"analysis_results\": analysis_results}\n",
        "    except Exception as e:\n",
        "        return {\"error_message\": f\"Node G failed: {e}\"}"
      ],
      "metadata": {
        "id": "Bo9I3eEEPVcB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==================================\n",
        "# NODE H: Generate Narrative\n",
        "# Purpose: Takes all the structured facts and insights generated by the\n",
        "#          previous nodes and uses Gemini to synthesize a final,\n",
        "#          human-readable executive summary.\n",
        "# ==================================\n",
        "def node_h_generate_narrative(state: AgentState) -> dict:\n",
        "    \"\"\"Creates the final human-readable report.\"\"\"\n",
        "    print(\"\\n[Node H: Generate Narrative]\")\n",
        "    try:\n",
        "        analysis_results = state[\"analysis_results\"]\n",
        "        # Prepare the facts for the AI prompt\n",
        "        summary = analysis_results.get(\"summary\", {})\n",
        "        drivers = analysis_results.get(\"drivers_final\", [])\n",
        "        qualitative_obs = analysis_results.get(\"qualitative_analysis\", {}).get(\"observations\", [])\n",
        "\n",
        "        # Create a clean, text-based summary of the top drivers\n",
        "        top_drivers_text = \"\\n\".join([f\"- {d['driver']}: {d['delta_pp']:.2f}pp ({d['type']})\" for d in drivers[:5]])\n",
        "        qualitative_text = \"\\n\".join([f\"- {obs}\" for obs in qualitative_obs])\n",
        "\n",
        "        model = genai.GenerativeModel(\"gemini-2.5-pro\")\n",
        "        prompt = f\"\"\"\n",
        "        You are a senior business analyst delivering a final report.\n",
        "        Your task is to create a concise, actionable summary based *only* on the facts provided.\n",
        "\n",
        "        **Fact Sheet:**\n",
        "        - **Overall Summary:** Conversion rate changed from {summary.get('baseline_cr_pct'):.2f}% to {summary.get('analysis_cr_pct'):.2f}%, a change of {summary.get('delta_cr_pp'):.2f} percentage points.\n",
        "        - **Top Quantitative Drivers:**\n",
        "        {top_drivers_text}\n",
        "        - **High-Level Qualitative Observations:**\n",
        "        {qualitative_text}\n",
        "\n",
        "        **Your Output:**\n",
        "        Provide a final report with the following structure:\n",
        "        1.  **Executive Summary:** 2-3 sentences summarizing the key takeaway.\n",
        "        2.  **What Changed:** A bulleted list of the top 2-3 drivers. For each driver, explain *what* happened in simple terms.\n",
        "        3.  **Actionable Recommendations:** 1-2 concrete, actionable next steps based directly on the findings.\n",
        "        4.  **Hypotheses (Optional):** If you have ideas that are *not* directly supported by the data, list them here under this specific heading.\n",
        "\n",
        "        Be clear, concise, and professional. Do not invent any facts.\n",
        "        \"\"\"\n",
        "        response = model.generate_content(prompt)\n",
        "        final_narrative = response.text\n",
        "        print(\"  - Output: Generated final narrative report.\")\n",
        "        return {\"final_narrative\": final_narrative}\n",
        "    except Exception as e:\n",
        "        return {\"error_message\": f\"Node H failed: {e}\"}"
      ],
      "metadata": {
        "id": "UvnoEI3iPgVK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# SECTION 4: GRAPH ASSEMBLY & ROUTING\n",
        "# Here, we wire all our functions together into a state machine.\n",
        "# ==============================================================================\n",
        "\n",
        "### --- Router Function --- ###\n",
        "def should_continue_router(state: AgentState) -> str:\n",
        "    \"\"\"The router that decides which path to take after Node B.\"\"\"\n",
        "    print(\"\\n[Router]\")\n",
        "    if state.get(\"error_message\"):\n",
        "        print(\"  - Decision: Error detected. Routing to end.\")\n",
        "        return \"end_error\"\n",
        "    if state.get(\"config\", {}).get(\"need_dates\", False):\n",
        "        print(\"  - Decision: Dates needed. Routing to end for clarification.\")\n",
        "        return \"end_clarify\"\n",
        "    else:\n",
        "        print(\"  - Decision: Config OK. Routing to main analysis path.\")\n",
        "        return \"continue_analysis\"\n",
        "\n",
        "### --- Graph Definition --- ###\n",
        "workflow = StateGraph(AgentState)\n",
        "\n",
        "# Add all nodes to the graph\n",
        "workflow.add_node(\"ingest\", node_a_ingest_and_clean)\n",
        "workflow.add_node(\"generate_config\", node_b_generate_config)\n",
        "workflow.add_node(\"calculate_metrics\", node_c_calculate_metrics)\n",
        "# The parallel analysis branches\n",
        "workflow.add_node(\"ai_analyst\", node_d_ai_analyst)\n",
        "workflow.add_node(\"performance_diagnostics\", node_e_performance_diagnostics)\n",
        "workflow.add_node(\"mix_diagnostics\", node_f_mix_diagnostics)\n",
        "# The composition nodes\n",
        "workflow.add_node(\"compose_waterfall\", node_g_compose_waterfall)\n",
        "workflow.add_node(\"generate_narrative\", node_h_generate_narrative)\n",
        "\n",
        "\n",
        "### --- Define Edges (the flow of the application) --- ###\n",
        "\n",
        "# 1. Start with the Ingest node\n",
        "workflow.set_entry_point(\"ingest\")\n",
        "\n",
        "# 2. From Ingest to Config Generation\n",
        "workflow.add_edge(\"ingest\", \"generate_config\")\n",
        "\n",
        "# 3. After Config Generation, use the router to decide the next step\n",
        "workflow.add_conditional_edges(\n",
        "    \"generate_config\",\n",
        "    should_continue_router,\n",
        "    {\"continue_analysis\": \"calculate_metrics\", \"end_clarify\": END, \"end_error\": END}\n",
        ")\n",
        "\n",
        "workflow.add_edge(\"calculate_metrics\", \"ai_analyst\")\n",
        "workflow.add_edge(\"ai_analyst\", \"performance_diagnostics\")\n",
        "workflow.add_edge(\"performance_diagnostics\", \"mix_diagnostics\")\n",
        "workflow.add_edge(\"mix_diagnostics\", \"compose_waterfall\")\n",
        "workflow.add_edge(\"compose_waterfall\", \"generate_narrative\")\n",
        "\n",
        "# 7. The final step is the end of the graph\n",
        "workflow.add_edge(\"generate_narrative\", END)\n",
        "\n",
        "### --- Compile the graph into a runnable app --- ###\n",
        "# We remove the checkpointer for simplicity as it was causing import errors.\n",
        "# The graph will be stateless between runs, but stateful within a single run.\n",
        "app = workflow.compile()\n",
        "print(\"\\nâœ… LangGraph app compiled successfully.\")"
      ],
      "metadata": {
        "id": "tNIXpEfePmZc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Agent Workflow Diagram ---\")\n",
        "# This command will render the visual graph directly in your Colab output.\n",
        "from IPython.display import Image, display\n",
        "display(Image(app.get_graph().draw_mermaid_png()))\n",
        "print(\"----------------------------\")"
      ],
      "metadata": {
        "id": "-2X6H1-aQS7i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# SECTION 5: USER INTERFACE & EXECUTION\n",
        "# This is the final part of the script that the user interacts with.\n",
        "# ==============================================================================\n",
        "\n",
        "print(\"\\n\\n--- Starting CRO Analytics Agent ---\")\n",
        "\n",
        "# --- Step 1: Upload File ---\n",
        "# This uses the Colab 'files' library imported in Section 1.\n",
        "print(\"Please upload your CRO data CSV file...\")\n",
        "uploaded = files.upload()\n",
        "if not uploaded:\n",
        "    raise Exception(\"No file uploaded. Halting execution.\")\n",
        "raw_file_path = next(iter(uploaded))\n",
        "\n",
        "# --- Step 2: Get Question ---\n",
        "# The input() function creates a text box for the user to type in.\n",
        "question = input(\"\\n>>> Please ask a complete question (e.g., 'Why did CR drop last week vs the week before?'): \")\n",
        "\n",
        "# --- Step 3: Run the Agent ---\n",
        "# Define the initial state to kick off the graph.\n",
        "initial_state = {\n",
        "    \"raw_data_path\": raw_file_path,\n",
        "    \"user_question\": question,\n",
        "}\n",
        "\n",
        "# The 'invoke' command runs the entire graph from the entry point to an end point.\n",
        "# It passes the 'initial_state' to the first node.\n",
        "final_state = app.invoke(initial_state)\n",
        "\n",
        "# --- Step 4: Display the Final Output ---\n",
        "# After the graph has finished running, we inspect the final state.\n",
        "print(\"\\n\\nðŸŽ‰ --- Agent Execution Complete --- ðŸŽ‰\")\n",
        "if final_state.get(\"error_message\"):\n",
        "    # If any node returned an error, we display it.\n",
        "    print(f\"ðŸš¨ Agent stopped with an error: {final_state.get('error_message')}\")\n",
        "elif final_state.get(\"config\", {}).get(\"need_dates\"):\n",
        "    # If the router stopped because dates were needed, we display the AI's message.\n",
        "    print(f\"ðŸ’¡ AI needs more information: {final_state.get('config', {}).get('message')}\")\n",
        "else:\n",
        "    # If the graph ran successfully, we display the final report.\n",
        "    print(\"\\n==================================================\")\n",
        "    print(\"           Final Executive Summary\")\n",
        "    print(\"==================================================\")\n",
        "    # Print the final narrative generated by Node H.\n",
        "    print(final_state.get(\"final_narrative\", \"No narrative was generated.\"))\n",
        "    print(\"\\n\")"
      ],
      "metadata": {
        "id": "qCwKYbYeRDp3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}